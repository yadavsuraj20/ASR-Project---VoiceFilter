{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset Generation - VoiceFilter.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fsd6mxpD7IKO",
        "Tkq6P3N87fuJ"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashwardhan-gautam/Grid2.0/blob/master/VoiceFilter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrDLpdjNLgr5"
      },
      "source": [
        "### Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftiq8OW-g9sh",
        "outputId": "d5b909ea-0ee9-40a6-e6e5-6c61ebcdda43"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpTNOZ6AJaTC"
      },
      "source": [
        "### Basic necessary definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9EI3iMVPm_O"
      },
      "source": [
        "#### Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gtuWy1rMkT9"
      },
      "source": [
        "class HyperParams:\n",
        "  n_fft= 1200\n",
        "  num_freq= 601 # n_fft//2 + 1\n",
        "  sample_rate= 16000\n",
        "  hop_length= 160\n",
        "  win_length= 400\n",
        "  min_level_db= -100.0\n",
        "  ref_level_db= 20.0\n",
        "  preemphasis= 0.97\n",
        "  power= 0.30\n",
        "  embedder_window= 80\n",
        "  data_audio_len= 3.0\n",
        "  embedder_num_mels= 40\n",
        "  embedder_lstm_hidden = 768\n",
        "  embedder_emb_dim = 256\n",
        "  embedder_lstm_layers = 3\n",
        "  embedder_window = 80\n",
        "  embedder_stride = 40\n",
        "  model_lstm_dim = 400\n",
        "  model_fc1_dim = 600\n",
        "  model_fc2_dim = 601 # num_freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yntexUgzKhPd"
      },
      "source": [
        "#### Audio related helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPudQJeEMfvX"
      },
      "source": [
        "import librosa\n",
        "import numpy as np  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgCTVz6FKlNB"
      },
      "source": [
        "class Audio:\n",
        "  def __init__(self,hyper_params):\n",
        "    self.hyper_params = hyper_params\n",
        "    self.mel_basis_matrix = librosa.filters.mel(sr=hyper_params.sample_rate,\n",
        "                                             n_fft=hyper_params.n_fft,\n",
        "                                             n_mels=hyper_params.embedder_num_mels);\n",
        "\n",
        "  def get_mel_spec(self,wave):\n",
        "    spec = librosa.core.stft(y=wave, n_fft=self.hyper_params.n_fft,\n",
        "                              hop_length=self.hyper_params.hop_length,\n",
        "                              win_length=self.hyper_params.win_length,\n",
        "                              window='hann')\n",
        "    power_spec = np.abs(spec) ** 2\n",
        "    mel_spec = np.log10(np.dot(self.mel_basis_matrix,power_spec)+1e-6)\n",
        "    return mel_spec  \n",
        "  def wave2spec(self,wave): \n",
        "    spec = librosa.core.stft(y=wave, n_fft=self.hyper_params.n_fft,\n",
        "                            hop_length=self.hyper_params.hop_length,\n",
        "                            win_length=self.hyper_params.win_length)\n",
        "    phase = np.angle(spec)\n",
        "    spec_db = self.amp2db(np.abs(spec))\n",
        "    spec_db_norm = self.normalize(spec_db)\n",
        "    spec_db_norm = spec_db_norm.T   # Taking transpose here\n",
        "    phase = phase.T # Taking transpose here\n",
        "    return spec_db_norm, phase\n",
        "  def spec2wave(self,spec_db_norm,phase):\n",
        "    spec_db_norm, phase = spec_db_norm.T, phase.T\n",
        "    spec_db = self.denormalize(spec_db_norm)\n",
        "    spec_amp = self.db2amp(spec_db)\n",
        "    spec = spec_amp * np.exp(1j*phase)\n",
        "    wave = librosa.core.istft(spec,\n",
        "                             hop_length=self.hyper_params.hop_length,\n",
        "                             win_length=self.hyper_params.win_length)\n",
        "    return wave\n",
        "  def amp2db(self,mat):\n",
        "    return 20.0 * np.log10(np.maximum(1e-5,mat)) - self.hyper_params.ref_level_db\n",
        "  def db2amp(self,mat):\n",
        "    return np.power(10.0, (mat+self.hyper_params.ref_level_db)*0.05)\n",
        "  def normalize(self,mat):\n",
        "    return np.clip((mat-self.hyper_params.min_level_db)/-self.hyper_params.min_level_db, 0.0 , 1.0)\n",
        "  def denormalize(self, mat):\n",
        "    return np.clip(mat,0.0,1.0)*(-self.hyper_params.min_level_db)+self.hyper_params.min_level_db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpby8NOId17k"
      },
      "source": [
        "hyper_params = HyperParams()\n",
        "audio = Audio(hyper_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n7Rp8QqJy5g"
      },
      "source": [
        "#### Define paths and create folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGdrkrxsKCZC"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DpEldXBJ9VI"
      },
      "source": [
        "# dataset_path = os.path.join('drive','MyDrive','CS753 ASR Project','LibriSpeech Dataset');\n",
        "!mkdir './LibriSpeech Dataset'\n",
        "dataset_path = os.path.join('./LibriSpeech Dataset');\n",
        "path = {}\n",
        "path['train'] = os.path.join(dataset_path ,'LibriSpeech Train Dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NciVTRuccLj8"
      },
      "source": [
        "# !rm -r 'LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/'\n",
        "# !rm -r 'LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/'\n",
        "# !rm -r 'LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/'\n",
        "# !rm -r 'LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/'\n",
        "# !rm -r 'LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/'\n",
        "# !rm -r 'LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv'\n",
        "# !rm -r 'LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPV7WUzSJbda",
        "outputId": "0d89b9c8-8990-404e-d1b7-42df5986e6af"
      },
      "source": [
        "# create directories to store dataset\n",
        "for dataset in ['train']:\n",
        "  os.makedirs(os.path.join(path[dataset],'input_spec'),exist_ok=True)\n",
        "  os.makedirs(os.path.join(path[dataset],'output_spec'),exist_ok=True)\n",
        "  os.makedirs(os.path.join(path[dataset],'input_phase'),exist_ok=True)\n",
        "  os.makedirs(os.path.join(path[dataset],'output_phase'),exist_ok=True)\n",
        "  os.makedirs(os.path.join(path[dataset],'dvec'),exist_ok=True)\n",
        "print('Directories created')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directories created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phzSLGUM4Lxv",
        "outputId": "5107747a-c1f8-414e-ec86-13b370f42bb3"
      },
      "source": [
        "# create 8 separate directories for training dataset to avoid issues with gdrive\n",
        "def create_folders(i):\n",
        "  os.makedirs(os.path.join(path['train'],'input_spec_'+i),exist_ok=True)\n",
        "  os.makedirs(os.path.join(path['train'],'output_spec_'+i),exist_ok=True)\n",
        "  os.makedirs(os.path.join(path['train'],'input_phase_'+i),exist_ok=True)\n",
        "  os.makedirs(os.path.join(path['train'],'output_phase_'+i),exist_ok=True)\n",
        "  os.makedirs(os.path.join(path['train'],'dvec_'+i),exist_ok=True)\n",
        "\n",
        "for i in range(8):\n",
        "  create_folders(str(i))\n",
        "print('Directories created')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directories created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5xk_DX2Kl3K"
      },
      "source": [
        "### Unzip LibriSpeech dataset ( Execute just once )\n",
        "ALREADY DONE IN DATA PREPARATION. DO NOT REPEAT.\n",
        "\n",
        "ALSO, USE LINUX COMMANDS TO FIRST EXTRACT DATASETS IN VM, AND THEN MOVE TO DRIVE INSTEAD OF USING SHUTIL TO DIRECTLY EXTRACT IN DRIVE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvxLkLTHoM3V"
      },
      "source": [
        "# import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROSA0GeTpUeZ"
      },
      "source": [
        "# shutil.unpack_archive(dataset_path+'/train-clean-100.tar.gz',dataset_path)\n",
        "# Rename the extracted folder LibriSpeech to LibriSpeech Train Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2vjYkyboOc6"
      },
      "source": [
        "# shutil.unpack_archive(dataset_path+'/dev-clean.tar.gz',dataset_path)\n",
        "# Rename the extracted folder LibriSpeech to LibriSpeech Dev Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKdA7umOpBk7"
      },
      "source": [
        "# shutil.unpack_archive(dataset_path+'/test-clean.tar.gz',dataset_path)\n",
        "# Rename the extracted folder LibriSpeech to LibriSpeech Test Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8MugiyehIT2"
      },
      "source": [
        "# !rm -r \"drive/MyDrive/LibriSpeech Dataset/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH-MI9-5fZnG"
      },
      "source": [
        "# !mkdir \"drive/MyDrive/LibriSpeech Dataset/\"\n",
        "# !mkdir \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Test Dataset\"\n",
        "# !mkdir \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Dev Dataset\"\n",
        "# !mkdir \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset\"\n",
        "\n",
        "# %ls \"drive/MyDrive/LibriSpeech Dataset/\"\n",
        "\n",
        "# %cd \"LibriSpeech Dataset/\"\n",
        "\n",
        "# !wget https://www.openslr.org/resources/12/test-clean.tar.gz\n",
        "# !time cp \"test-clean.tar.gz\" \"../drive/MyDrive/LibriSpeech Dataset/\"\n",
        "# !tar -xf \"test-clean.tar.gz\"\n",
        "# !mv LibriSpeech \"LibriSpeech Test Dataset\"\n",
        "\n",
        "# !wget https://www.openslr.org/resources/12/dev-clean.tar.gz\n",
        "# !time cp \"dev-clean.tar.gz\" \"../drive/MyDrive/LibriSpeech Dataset/\"\n",
        "# !tar -xf \"dev-clean.tar.gz\"\n",
        "# !mv LibriSpeech \"LibriSpeech Dev Dataset\"\n",
        "\n",
        "# !wget https://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
        "# !time cp \"train-clean-100.tar.gz\" \"../drive/MyDrive/LibriSpeech Dataset/\" # approx 4 mins\n",
        "# !tar -xf \"train-clean-100.tar.gz\"\n",
        "# !mv LibriSpeech \"LibriSpeech Train Dataset\"\n",
        "\n",
        "# !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1YFmhmUok-W76JkrfA0fzQt3c-ZsfiwfL' -O embedder.pt\n",
        "# !cp embedder.pt \"../drive/MyDrive/LibriSpeech Dataset/\"\n",
        "\n",
        "# %cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMMzJpDkplv7",
        "outputId": "35c12fce-2573-44c0-d6ed-21b2e17c7216"
      },
      "source": [
        "# takes approx 6 mins\n",
        "%cd \"LibriSpeech Dataset/\"\n",
        "!time cp \"../drive/MyDrive/LibriSpeech Dataset/train-clean-100.tar.gz\" .\n",
        "!time tar -xf train-clean-100.tar.gz\n",
        "!mv LibriSpeech \"LibriSpeech Train Dataset\"\n",
        "!rm train-clean-100.tar.gz\n",
        "\n",
        "!time cp \"../drive/MyDrive/LibriSpeech Dataset/embedder.pt\" .\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LibriSpeech Dataset\n",
            "\n",
            "real\t3m10.948s\n",
            "user\t0m0.023s\n",
            "sys\t0m8.008s\n",
            "\n",
            "real\t1m48.763s\n",
            "user\t0m40.370s\n",
            "sys\t0m20.359s\n",
            "\n",
            "real\t0m11.335s\n",
            "user\t0m0.002s\n",
            "sys\t0m0.054s\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3ONj9rOpt4r"
      },
      "source": [
        "# ## takes approx 35 mins\n",
        "# ## copy train dataset\n",
        "# %cd \"LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "\n",
        "# !time cp \"../../drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/dvec5.tar\" .\n",
        "# !time tar -xf dvec5.tar\n",
        "# !mv \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\" .\n",
        "# !rm -r \"LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm dvec5.tar\n",
        "# print(\"dvec done\")\n",
        "\n",
        "# !time cp \"../../drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase5.tar\" .\n",
        "# !time tar -xf input_phase5.tar\n",
        "# !mv \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\" .\n",
        "# !rm -r \"LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm input_phase5.tar\n",
        "# print(\"input_phase done\")\n",
        "\n",
        "# !time cp \"../../drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase5.tar\" .\n",
        "# !time tar -xf output_phase5.tar\n",
        "# !mv \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\" .\n",
        "# !rm -r \"LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm output_phase5.tar\n",
        "# print(\"output_phase done\")\n",
        "\n",
        "# !time cp \"../../drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec5.tar\" .\n",
        "# !time tar -xf input_spec5.tar\n",
        "# !mv \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\" .\n",
        "# !rm -r \"LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm input_spec5.tar\n",
        "# print(\"input_spec done\")\n",
        "\n",
        "# !time cp \"../../drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec5.tar\" .\n",
        "# !time tar -xf output_spec5.tar\n",
        "# !mv \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\" .\n",
        "# !rm -r \"LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm output_spec5.tar\n",
        "# print(\"output_spec done\")\n",
        "\n",
        "# !time cp \"../../drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches5.data\" train_speeches.data\n",
        "# !time cp \"../../drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame5.csv\" data_frame.csv\n",
        "# print(\"ALL done\")\n",
        "\n",
        "# %cd ../..\n",
        "\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\" | wc -l\n",
        "# !wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\"\n",
        "# !wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRzpalU3KwNP"
      },
      "source": [
        "### Create and store speech collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybeXYLLn6y6S"
      },
      "source": [
        "import glob\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynOAUrMGLPgU"
      },
      "source": [
        "#### Run this cell only the first time ####\n",
        "# dev_base_path = os.path.join(path['dev'],'LibriSpeech','dev-clean')\n",
        "# test_base_path = os.path.join(path['test'],'LibriSpeech','test-clean')\n",
        "train_base_path = os.path.join(path['train'],'LibriSpeech','train-clean-100')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE-SiXAC5nNC"
      },
      "source": [
        "#### Run this cell only the first time ####\n",
        "# dev_spks = os.listdir(dev_base_path)\n",
        "# list of all speaker folders\n",
        "# dev_speeches = [glob.glob(os.path.join(dev_base_path,spk,'*','*.flac'),recursive=True) for spk in dev_spks]\n",
        "# dev_speeches = [speeches for speeches in dev_speeches if len(speeches)>=2]\n",
        "# list of lists containing speeches of a speaker\n",
        "# test_spks = os.listdir(test_base_path)\n",
        "# list of all speaker folders\n",
        "# test_speeches = [glob.glob(os.path.join(test_base_path,spk,'*','*.flac'),recursive=True) for spk in test_spks]\n",
        "# test_speeches = [speeches for speeches in test_speeches if len(speeches)>=2]\n",
        "# list of lists containing speeches of a speaker\n",
        "train_spks = os.listdir(train_base_path)\n",
        "# list of all speaker folders\n",
        "train_speeches = [glob.glob(os.path.join(train_base_path,spk,'*','*.flac'),recursive=True) for spk in train_spks]\n",
        "train_speeches = [speeches for speeches in train_speeches if len(speeches)>=2]\n",
        "# list of lists containing speeches of a speaker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhn64N6Hx3pN"
      },
      "source": [
        "#### Run this cell only the first time #####\n",
        "# with open(os.path.join(path['dev'],'dev_speeches.data'),'wb') as f:\n",
        "#   pickle.dump(dev_speeches,f)\n",
        "# with open(os.path.join(path['test'],'test_speeches.data'),'wb') as f:\n",
        "#   pickle.dump(test_speeches,f)\n",
        "with open(os.path.join(path['train'],'train_speeches.data'),'wb') as f:\n",
        "  pickle.dump(train_speeches,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJz_tFRhyat7"
      },
      "source": [
        "# with open(os.path.join(path['dev'],'dev_speeches.data'),'rb') as f:\n",
        "#   dev_speeches = pickle.load(f)\n",
        "# with open(os.path.join(path['test'],'test_speeches.data'),'rb') as f:\n",
        "#   test_speeches = pickle.load(f)\n",
        "with open(os.path.join(path['train'],'train_speeches.data'),'rb') as f:\n",
        "  train_speeches = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EDQM5HyLB_n"
      },
      "source": [
        "### Use pre trained model to obtain Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL0iLkzaLNLr"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, hp):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear_layer = nn.Linear(hp.embedder_lstm_hidden, hp.embedder_emb_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear_layer(x)\n",
        "\n",
        "\n",
        "class SpeechEmbedder(nn.Module):\n",
        "    def __init__(self, hp):\n",
        "        super(SpeechEmbedder, self).__init__()\n",
        "        self.lstm = nn.LSTM(hp.embedder_num_mels,\n",
        "                            hp.embedder_lstm_hidden,\n",
        "                            num_layers=hp.embedder_lstm_layers,\n",
        "                            batch_first=True)\n",
        "        self.proj = LinearNorm(hp)\n",
        "        self.hp = hp\n",
        "\n",
        "    def forward(self, mel):\n",
        "        # (num_mels, T)\n",
        "        mels = mel.unfold(1, self.hp.embedder_window, self.hp.embedder_stride) # (num_mels, T', window)\n",
        "        mels = mels.permute(1, 2, 0) # (T', window, num_mels)\n",
        "        # print(\"h1\")\n",
        "        x, _ = self.lstm(mels) # (T', window, lstm_hidden)\n",
        "        # print(\"h2\")\n",
        "        x = x[:, -1, :] # (T', lstm_hidden), use last frame only\n",
        "        x = self.proj(x) # (T', emb_dim)\n",
        "        x = x / torch.norm(x, p=2, dim=1, keepdim=True) # (T', emb_dim)\n",
        "        x = x.sum(0) / x.size(0) # (emb_dim), average pooling over time frames\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LohsR5EFgzCq",
        "outputId": "d3f0dba6-550b-4460-a98e-e2bf330f5e6c"
      },
      "source": [
        "# Embedder downloaded from https://drive.google.com/file/d/1YFmhmUok-W76JkrfA0fzQt3c-ZsfiwfL/view (https://github.com/mindslab-ai/voicefilter)\n",
        "embedder_path = os.path.join(dataset_path,\"embedder.pt\")\n",
        "embedder_pt = torch.load(embedder_path,map_location=torch.device('cpu'))\n",
        "embedder = SpeechEmbedder(hyper_params)\n",
        "embedder.load_state_dict(embedder_pt)\n",
        "embedder.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpeechEmbedder(\n",
              "  (lstm): LSTM(40, 768, num_layers=3, batch_first=True)\n",
              "  (proj): LinearNorm(\n",
              "    (linear_layer): Linear(in_features=768, out_features=256, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvgVzESG4KPP"
      },
      "source": [
        "### Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6Tq5UGxZSvm"
      },
      "source": [
        "import random\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3tNz2zmi03Y"
      },
      "source": [
        "# returns dvec for the input wave using pre trained embedder model\n",
        "def get_dvector(wave):\n",
        "  mel_spec = audio.get_mel_spec(wave)\n",
        "  dvec = embedder(torch.from_numpy(mel_spec).float())\n",
        "  dvec = dvec.detach().numpy()\n",
        "  return dvec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMj31NLj-c0g"
      },
      "source": [
        "# pre process waves and store spectrogram, phase and dvector in their respective folders\n",
        "def create_example(target_dir, hyper_params, idx, ref_speech, pri_speech, sec_speech):\n",
        "  sample_rate = hyper_params.sample_rate\n",
        "  ref_wave, _ = librosa.load(ref_speech,sr=sample_rate) #load the audio file\n",
        "  pri_wave, _ = librosa.load(pri_speech, sr = sample_rate)\n",
        "  sec_wave,_ = librosa.load(sec_speech, sr = sample_rate)\n",
        "  assert len(ref_wave.shape)==len(pri_wave.shape)==len(sec_wave.shape)==1,\\\n",
        "  'wave files must be mono and not stereo'\n",
        "  ref_wave,_ = librosa.effects.trim(ref_wave, top_db = 20) # clip silent portion on both ends\n",
        "  pri_wave,_ = librosa.effects.trim(pri_wave, top_db = 20)\n",
        "  sec_wave,_ = librosa.effects.trim(sec_wave, top_db = 20)\n",
        "  \n",
        "  if ref_wave.shape[0] < 1.1 * hyper_params.embedder_window * hyper_params.hop_length :\n",
        "    return\n",
        "  length_wave = int(sample_rate * hyper_params.data_audio_len)\n",
        "  if pri_wave.shape[0]<length_wave or sec_wave.shape[0]<length_wave:\n",
        "    return\n",
        "  pri_wave, sec_wave = pri_wave[:length_wave], sec_wave[:length_wave] # clip wave to fixed length\n",
        "  mix_wave = pri_wave + sec_wave\n",
        "  norm = np.max(np.abs(mix_wave)) * 1.1\n",
        "  pri_wave, mix_wave = pri_wave/norm , mix_wave/norm  # normalize wave by 1.1*max(absolute amplitude)\n",
        "  pri_spec, pri_phase = audio.wave2spec(pri_wave)  # convert wave to spec\n",
        "  mix_spec, mix_phase = audio.wave2spec(mix_wave)\n",
        "  dvec = get_dvector(ref_wave)\n",
        "\n",
        "  # paths for storing data\n",
        "  pri_spec_path = os.path.join(target_dir,'output_spec','%06d.npy'%idx)\n",
        "  pri_phase_path = os.path.join(target_dir,'output_phase','%06d.npy'%idx)\n",
        "  mix_spec_path = os.path.join(target_dir, 'input_spec','%06d.npy'%idx)\n",
        "  mix_phase_path = os.path.join(target_dir,'input_phase','%06d.npy'%idx)\n",
        "  dvec_path = os.path.join(target_dir,'dvec','%06d.npy'%idx)\n",
        "  # store data on paths above\n",
        "  np.save(pri_spec_path,pri_spec)\n",
        "  np.save(mix_spec_path,mix_spec)\n",
        "  np.save(mix_phase_path, mix_phase)\n",
        "  np.save(pri_phase_path, pri_phase)\n",
        "  np.save(dvec_path,dvec)\n",
        "\n",
        "  #print(idx)\n",
        "  return [idx, ref_speech, pri_speech, sec_speech,  mix_spec_path, pri_spec_path, mix_phase_path, pri_phase_path, dvec_path]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb8gOEtANbYZ"
      },
      "source": [
        "columns=['key','ref_speech','pri_speech','sec_speech','input_spec_path','output_spec_path','input_phase_path','output_phase_path','dvec_path']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6QxtMeHJ9vD"
      },
      "source": [
        "### to be run just once ####\n",
        "sample_data_frame = pd.DataFrame(data = [], columns=columns)\n",
        "for dataset in ['train']:\n",
        "  sample_data_frame.to_csv(os.path.join(path[dataset],'data_frame.csv'),index=False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQsg2OgxwZcW"
      },
      "source": [
        "def create_dataset(i):\n",
        "  batch = []\n",
        "  array = range(i+1,n+1)\n",
        "  if parity == 1:\n",
        "    array = range(1,i)\n",
        "  for j in array:\n",
        "    first = min(i,j)\n",
        "    sec = max(i,j)\n",
        "    if (sec-first)%2 == parity:\n",
        "      first, sec = sec, first\n",
        "    n1 = len(speeches[first-1]) # -1 accounts for zero based indexing\n",
        "    n2 = len(speeches[sec-1]) # -1 accounts for zero based indexing\n",
        "    sum = first+sec-1 # -1 accounts for zero based indexing\n",
        "    diff = first-sec-1 # -1 accounts for zero based indexing\n",
        "    diff_mod = (abs(diff))%n1\n",
        "    if diff < 0 and diff_mod > 0:\n",
        "      diff_mod = n1 - diff_mod\n",
        "    ref_speech = speeches[first-1][diff_mod]\n",
        "    pri_speech = speeches[first-1][sum%n1]\n",
        "    sec_speech = speeches[sec-1][first%n2]\n",
        "    row = create_example( path[dataset], hyper_params , n*(i-1) + j, ref_speech, pri_speech, sec_speech)\n",
        "    if row is not None:\n",
        "      batch.append(row)\n",
        "  print(i)\n",
        "  data.extend(batch)\n",
        "  return batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8QXfbd4BcP4"
      },
      "source": [
        "def save_batch(dataset,data):\n",
        "  df_path = os.path.join(path[dataset],'data_frame.csv')\n",
        "  df = pd.read_csv(df_path)\n",
        "  df_batch = pd.DataFrame(data = data, columns = columns)\n",
        "  df = df.append(df_batch)\n",
        "  df.to_csv(df_path,index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqrl0maVfwuJ"
      },
      "source": [
        "import os\n",
        "import time\n",
        "from multiprocessing import Pool\n",
        "cpu_num = len(os.sched_getaffinity(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnaWGySu3acM",
        "outputId": "078bb5bb-b492-4a0b-ff16-f0a6564cb0b7"
      },
      "source": [
        "print(\"Number of cpu available : \",cpu_num)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of cpu available :  40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xYjnqKY46-3"
      },
      "source": [
        "#### Train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZGW44jY34F8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db920522-320a-4e1c-f02b-c1a2358696b6"
      },
      "source": [
        "dataset = 'train' # important global variable\n",
        "speeches = train_speeches # important global variable\n",
        "# n = len(train_speeches) # important global variable\n",
        "n = 200  ## to speedup train dataset\n",
        "print(\"number of speakers(train set) : \",n)\n",
        "for i in range(n):\n",
        "  random.shuffle(train_speeches[i])  # shuffle the speeches of all speakers\n",
        "arr = list(range(1,n+1))  # create a list for all speakers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of speakers(train set) :  200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsd6mxpD7IKO"
      },
      "source": [
        "##### 0-100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPzyo_Ur4DUV"
      },
      "source": [
        "# data = []\n",
        "# parity = 0 # important global variable\n",
        "# x = time.time()\n",
        "# with Pool(cpu_num) as p:\n",
        "#   res = p.map(create_dataset, arr[0:25] , 4)\n",
        "# for batch in res:\n",
        "#   if len(batch) > 0:\n",
        "#     data.extend(batch)\n",
        "# y = time.time()\n",
        "# print(y-x)\n",
        "# save_batch('train',data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7g0qwtf2urJ"
      },
      "source": [
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\" | wc -l\n",
        "# !wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\"\n",
        "# !wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\"\n",
        "\n",
        "# !time tar -cf dvec1.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\"\n",
        "# !time cp dvec1.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm dvec1.tar\n",
        "\n",
        "# !time tar -cf input_phase1.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\"\n",
        "# !time cp input_phase1.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm input_phase1.tar\n",
        "\n",
        "# !time tar -cf output_phase1.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\"\n",
        "# !time cp output_phase1.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm output_phase1.tar\n",
        "\n",
        "# !time tar -cf input_spec1.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\"\n",
        "# !time cp input_spec1.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm input_spec1.tar\n",
        "\n",
        "# !time tar -cf output_spec1.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\"\n",
        "# !time cp output_spec1.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm output_spec1.tar\n",
        "\n",
        "# !time cp \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\" \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches1.data\"\n",
        "# !time cp \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\" \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame1.csv\"\n",
        "\n",
        "# %ls \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset\"\n",
        "\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/dvec1.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase1.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase1.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec1.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec1.tar\" | wc -l\n",
        "# !wc -l \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches1.data\"\n",
        "# !wc -l \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame1.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch_Yr5jJ4gLP"
      },
      "source": [
        "# data = []\n",
        "# parity = 0 # important global variable\n",
        "# x = time.time()\n",
        "# with Pool(cpu_num) as p:\n",
        "#   res = p.map(create_dataset, arr[25:50] , 4)\n",
        "# for batch in res:\n",
        "#   if len(batch) > 0:\n",
        "#     data.extend(batch)\n",
        "# y = time.time()\n",
        "# print(y-x)\n",
        "# save_batch('train',data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_p8ABLm9muC"
      },
      "source": [
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\" | wc -l\n",
        "# !wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\"\n",
        "# !wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\"\n",
        "\n",
        "# !time tar -cf dvec2.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\"\n",
        "# !time cp dvec2.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm dvec2.tar\n",
        "\n",
        "# !time tar -cf input_phase2.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\"\n",
        "# !time cp input_phase2.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm input_phase2.tar\n",
        "\n",
        "# !time tar -cf output_phase2.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\"\n",
        "# !time cp output_phase2.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm output_phase2.tar\n",
        "\n",
        "# !time tar -cf input_spec2.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\"\n",
        "# !time cp input_spec2.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm input_spec2.tar\n",
        "\n",
        "# !time tar -cf output_spec2.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\"\n",
        "# !time cp output_spec2.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm output_spec2.tar\n",
        "\n",
        "# !time cp \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\" \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches2.data\"\n",
        "# !time cp \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\" \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame2.csv\"\n",
        "\n",
        "# %ls \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset\"\n",
        "\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/dvec2.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase2.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase2.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec2.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec2.tar\" | wc -l\n",
        "# !wc -l \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches2.data\"\n",
        "# !wc -l \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame2.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyosHTRS4g26"
      },
      "source": [
        "# data = []\n",
        "# parity = 0 # important global variable\n",
        "# x = time.time()\n",
        "# with Pool(cpu_num) as p:\n",
        "#   res = p.map(create_dataset, arr[50:75] , 4)\n",
        "# for batch in res:\n",
        "#   if len(batch) > 0:\n",
        "#     data.extend(batch)\n",
        "# y = time.time()\n",
        "# print(y-x)\n",
        "# save_batch('train',data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnFbgM3i9oTT"
      },
      "source": [
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\" | wc -l\n",
        "# !wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\"\n",
        "# !wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\"\n",
        "\n",
        "# !time tar -cf dvec3.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\"\n",
        "# !time cp dvec3.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm dvec3.tar\n",
        "\n",
        "# !time tar -cf input_phase3.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\"\n",
        "# !time cp input_phase3.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm input_phase3.tar\n",
        "\n",
        "# !time tar -cf output_phase3.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\"\n",
        "# !time cp output_phase3.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm output_phase3.tar\n",
        "\n",
        "# !time tar -cf input_spec3.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\"\n",
        "# !time cp input_spec3.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm input_spec3.tar\n",
        "\n",
        "# !time tar -cf output_spec3.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\"\n",
        "# !time cp output_spec3.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm output_spec3.tar\n",
        "\n",
        "# !time cp \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\" \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches3.data\"\n",
        "# !time cp \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\" \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame3.csv\"\n",
        "\n",
        "# # %ls \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset\"\n",
        "\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/dvec3.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase3.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase3.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec3.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec3.tar\" | wc -l\n",
        "# !wc -l \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches3.data\"\n",
        "# !wc -l \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame3.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBME13Ey4hyC"
      },
      "source": [
        "# data = []\n",
        "# parity = 0 # important global variable\n",
        "# x = time.time()\n",
        "# with Pool(cpu_num) as p:\n",
        "#   res = p.map(create_dataset, arr[75:100] , 4)\n",
        "# for batch in res:\n",
        "#   if len(batch) > 0:\n",
        "#     data.extend(batch)\n",
        "# y = time.time()\n",
        "# print(y-x)\n",
        "# save_batch('train',data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8HxrhRH9pyS"
      },
      "source": [
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\" | wc -l\n",
        "# !wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\"\n",
        "# !wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\"\n",
        "\n",
        "# !rm -r \"LibriSpeech Dataset/LibriSpeech Dev Dataset/\"\n",
        "# !rm -r \"LibriSpeech Dataset/LibriSpeech Test Dataset/\"\n",
        "# !rm -r \"LibriSpeech Dataset/LibriSpeech Train Dataset/LibriSpeech/\"\n",
        "\n",
        "# %ls \"LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !time tar -cf dvec4.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\"\n",
        "# !time cp dvec4.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm dvec4.tar\n",
        "\n",
        "# !time tar -cf input_phase4.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\"\n",
        "# !time cp input_phase4.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm input_phase4.tar\n",
        "\n",
        "# !time tar -cf output_phase4.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\"\n",
        "# !time cp output_phase4.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm output_phase4.tar\n",
        "\n",
        "# !time tar -cf input_spec4.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\"\n",
        "# !time cp input_spec4.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm input_spec4.tar\n",
        "\n",
        "# !time tar -cf output_spec4.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\"\n",
        "# !time cp output_spec4.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "# !rm output_spec4.tar\n",
        "\n",
        "# !time cp \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\" \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches4.data\"\n",
        "# !time cp \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\" \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame4.csv\"\n",
        "\n",
        "# %ls \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset\"\n",
        "\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/dvec4.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase4.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase4.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec4.tar\" | wc -l\n",
        "# !tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec4.tar\" | wc -l\n",
        "# !wc -l \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches4.data\"\n",
        "# !wc -l \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame4.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j0v-mHF6_nK"
      },
      "source": [
        "##### 100-200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBTV7QYY62Jh"
      },
      "source": [
        "# data = []\n",
        "# parity = 0 # important global variable\n",
        "# x = time.time()\n",
        "# with Pool(cpu_num) as p:\n",
        "#   res = p.map(create_dataset, arr[100:125] , 4)\n",
        "# for batch in res:\n",
        "#   if len(batch) > 0:\n",
        "#     data.extend(batch)\n",
        "# y = time.time()\n",
        "# print(y-x)\n",
        "# save_batch('train',data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0MUGxa865Ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282cfbd5-d91f-4b81-a3b7-36d936820851"
      },
      "source": [
        "import threading\n",
        "data = [] # important global variable\n",
        "parity = 0 # important global variable\n",
        "x = time.time()\n",
        "\n",
        "t = [0]*250\n",
        "\n",
        "for i in arr[125:150]:\n",
        "    t[i] = threading.Thread(target=create_dataset, args=(i,))\n",
        "    t[i].start()\n",
        "\n",
        "for i in arr[125:150]:\n",
        "    t[i].join()\n",
        "\n",
        "# for i in range(125,150):\n",
        "    # batch = create_dataset(i)\n",
        "# with Pool(cpu_num) as p:\n",
        "#   res = p.map(create_dataset, arr[125:150])\n",
        "# batch = create_dataset(125)\n",
        "# for batch in res:\n",
        "#   if len(batch) > 0:\n",
        "    # data.extend(batch)\n",
        "y = time.time()\n",
        "print(y-x)\n",
        "save_batch('train',data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "145\n",
            "150\n",
            "149\n",
            "148\n",
            "147\n",
            "133\n",
            "142\n",
            "146\n",
            "143\n",
            "141\n",
            "144\n",
            "131\n",
            "138\n",
            "140\n",
            "139\n",
            "129\n",
            "136\n",
            "135\n",
            "137\n",
            "134\n",
            "127\n",
            "126\n",
            "128\n",
            "130\n",
            "132\n",
            "521.9960467815399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3toXvyGUbHrr",
        "outputId": "abf0077a-4881-444f-a1e2-e058406d0115"
      },
      "source": [
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\" | wc -l\n",
        "!wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\"\n",
        "!wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1462\n",
            "1462\n",
            "1462\n",
            "1462\n",
            "1462\n",
            "369 LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\n",
            "1462 LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCJK1-FZ671r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6def07-139b-4e29-d733-3c290f01883b"
      },
      "source": [
        "import threading\n",
        "data = [] # important global variable\n",
        "parity = 0 # important global variable\n",
        "x = time.time()\n",
        "\n",
        "t = [0]*250\n",
        "\n",
        "for i in arr[150:175]:\n",
        "    t[i] = threading.Thread(target=create_dataset, args=(i,))\n",
        "    t[i].start()\n",
        "\n",
        "for i in arr[150:175]:\n",
        "    t[i].join()\n",
        "\n",
        "# for i in range(125,150):\n",
        "    # batch = create_dataset(i)\n",
        "# with Pool(cpu_num) as p:\n",
        "#   res = p.map(create_dataset, arr[125:150])\n",
        "# batch = create_dataset(125)\n",
        "# for batch in res:\n",
        "#   if len(batch) > 0:\n",
        "    # data.extend(batch)\n",
        "y = time.time()\n",
        "print(y-x)\n",
        "save_batch('train',data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "175\n",
            "170\n",
            "173\n",
            "172\n",
            "174\n",
            "169\n",
            "167\n",
            "163\n",
            "171\n",
            "165\n",
            "168\n",
            "162\n",
            "166\n",
            "164\n",
            "157\n",
            "155\n",
            "159\n",
            "161\n",
            "160\n",
            "156\n",
            "153\n",
            "158\n",
            "151\n",
            "152\n",
            "154\n",
            "305.95789551734924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_tOL0JVfHXT",
        "outputId": "024635a0-6bc1-49b9-fb06-fa8726eb78e0"
      },
      "source": [
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\" | wc -l\n",
        "!wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\"\n",
        "!wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2338\n",
            "2338\n",
            "2338\n",
            "2338\n",
            "2338\n",
            "369 LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\n",
            "2338 LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vOfKNtJ7ZaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80442e24-47c9-4655-d7e8-2cce45d85839"
      },
      "source": [
        "import threading\n",
        "data = [] # important global variable\n",
        "parity = 0 # important global variable\n",
        "x = time.time()\n",
        "\n",
        "t = [0]*250\n",
        "\n",
        "for i in arr[175:200]:\n",
        "    t[i] = threading.Thread(target=create_dataset, args=(i,))\n",
        "    t[i].start()\n",
        "\n",
        "for i in arr[175:200]:\n",
        "    t[i].join()\n",
        "\n",
        "# for i in range(125,150):\n",
        "    # batch = create_dataset(i)\n",
        "# with Pool(cpu_num) as p:\n",
        "#   res = p.map(create_dataset, arr[125:150])\n",
        "# batch = create_dataset(125)\n",
        "# for batch in res:\n",
        "#   if len(batch) > 0:\n",
        "    # data.extend(batch)\n",
        "y = time.time()\n",
        "print(y-x)\n",
        "save_batch('train',data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "199\n",
            "198\n",
            "196\n",
            "197\n",
            "195\n",
            "190\n",
            "194\n",
            "191\n",
            "192\n",
            "193\n",
            "188\n",
            "189\n",
            "186\n",
            "187\n",
            "185\n",
            "181\n",
            "183\n",
            "184\n",
            "182\n",
            "178\n",
            "180\n",
            "177\n",
            "179\n",
            "176\n",
            "102.64650416374207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvEIFW8afJ9w",
        "outputId": "17e14d9c-dc21-41c8-913b-83539d138def"
      },
      "source": [
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\" | wc -l\n",
        "!wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\"\n",
        "!wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2611\n",
            "2611\n",
            "2611\n",
            "2611\n",
            "2611\n",
            "369 LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\n",
            "2611 LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9Vd0mOT2EoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171b151f-90c5-4daf-c06b-9884c706cd7e"
      },
      "source": [
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\" | wc -l\n",
        "!wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\"\n",
        "!wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\"\n",
        "\n",
        "# !rm -r \"LibriSpeech Dataset/LibriSpeech Dev Dataset/\"\n",
        "# !rm -r \"LibriSpeech Dataset/LibriSpeech Test Dataset/\"\n",
        "# !rm -r \"LibriSpeech Dataset/LibriSpeech Train Dataset/LibriSpeech/\"\n",
        "# !rm -r \"LibriSpeech Dataset/train-clean-100.tar.gz\"\n",
        "\n",
        "%ls \"LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "!time tar -cf dvec8.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\"\n",
        "!time cp dvec8.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "!rm dvec8.tar\n",
        "\n",
        "!time tar -cf input_phase8.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\"\n",
        "!time cp input_phase8.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "!rm input_phase8.tar\n",
        "\n",
        "!time tar -cf output_phase8.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\"\n",
        "!time cp output_phase8.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "!rm output_phase8.tar\n",
        "\n",
        "!time tar -cf input_spec8.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\"\n",
        "!time cp input_spec8.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "!rm input_spec8.tar\n",
        "\n",
        "!time tar -cf output_spec8.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\"\n",
        "!time cp output_spec8.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "!rm output_spec8.tar\n",
        "\n",
        "!time cp \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\" \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches8.data\"\n",
        "!time cp \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\" \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame8.csv\"\n",
        "\n",
        "%ls \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset\"\n",
        "\n",
        "!tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/dvec8.tar\" | wc -l\n",
        "!tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase8.tar\" | wc -l\n",
        "!tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase8.tar\" | wc -l\n",
        "!tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec8.tar\" | wc -l\n",
        "!tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec8.tar\" | wc -l\n",
        "!wc -l \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches8.data\"\n",
        "!wc -l \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame8.csv\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2611\n",
            "2611\n",
            "2611\n",
            "2611\n",
            "2611\n",
            "369 LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\n",
            "2611 LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\n",
            "data_frame.csv  \u001b[0m\u001b[01;34minput_phase_1\u001b[0m/  \u001b[01;34minput_spec_4\u001b[0m/    \u001b[01;34moutput_phase_6\u001b[0m/\n",
            "\u001b[01;34mdvec\u001b[0m/           \u001b[01;34minput_phase_2\u001b[0m/  \u001b[01;34minput_spec_5\u001b[0m/    \u001b[01;34moutput_phase_7\u001b[0m/\n",
            "\u001b[01;34mdvec_0\u001b[0m/         \u001b[01;34minput_phase_3\u001b[0m/  \u001b[01;34minput_spec_6\u001b[0m/    \u001b[01;34moutput_spec\u001b[0m/\n",
            "\u001b[01;34mdvec_1\u001b[0m/         \u001b[01;34minput_phase_4\u001b[0m/  \u001b[01;34minput_spec_7\u001b[0m/    \u001b[01;34moutput_spec_0\u001b[0m/\n",
            "\u001b[01;34mdvec_2\u001b[0m/         \u001b[01;34minput_phase_5\u001b[0m/  \u001b[01;34mLibriSpeech\u001b[0m/     \u001b[01;34moutput_spec_1\u001b[0m/\n",
            "\u001b[01;34mdvec_3\u001b[0m/         \u001b[01;34minput_phase_6\u001b[0m/  \u001b[01;34moutput_phase\u001b[0m/    \u001b[01;34moutput_spec_2\u001b[0m/\n",
            "\u001b[01;34mdvec_4\u001b[0m/         \u001b[01;34minput_phase_7\u001b[0m/  \u001b[01;34moutput_phase_0\u001b[0m/  \u001b[01;34moutput_spec_3\u001b[0m/\n",
            "\u001b[01;34mdvec_5\u001b[0m/         \u001b[01;34minput_spec\u001b[0m/     \u001b[01;34moutput_phase_1\u001b[0m/  \u001b[01;34moutput_spec_4\u001b[0m/\n",
            "\u001b[01;34mdvec_6\u001b[0m/         \u001b[01;34minput_spec_0\u001b[0m/   \u001b[01;34moutput_phase_2\u001b[0m/  \u001b[01;34moutput_spec_5\u001b[0m/\n",
            "\u001b[01;34mdvec_7\u001b[0m/         \u001b[01;34minput_spec_1\u001b[0m/   \u001b[01;34moutput_phase_3\u001b[0m/  \u001b[01;34moutput_spec_6\u001b[0m/\n",
            "\u001b[01;34minput_phase\u001b[0m/    \u001b[01;34minput_spec_2\u001b[0m/   \u001b[01;34moutput_phase_4\u001b[0m/  \u001b[01;34moutput_spec_7\u001b[0m/\n",
            "\u001b[01;34minput_phase_0\u001b[0m/  \u001b[01;34minput_spec_3\u001b[0m/   \u001b[01;34moutput_phase_5\u001b[0m/  train_speeches.data\n",
            "\n",
            "real\t0m0.050s\n",
            "user\t0m0.007s\n",
            "sys\t0m0.036s\n",
            "\n",
            "real\t0m0.464s\n",
            "user\t0m0.004s\n",
            "sys\t0m0.009s\n",
            "\n",
            "real\t0m6.040s\n",
            "user\t0m0.035s\n",
            "sys\t0m2.517s\n",
            "\n",
            "real\t0m33.334s\n",
            "user\t0m0.019s\n",
            "sys\t0m2.482s\n",
            "\n",
            "real\t0m26.910s\n",
            "user\t0m0.065s\n",
            "sys\t0m2.931s\n",
            "\n",
            "real\t0m35.699s\n",
            "user\t0m0.033s\n",
            "sys\t0m2.156s\n",
            "\n",
            "real\t0m34.291s\n",
            "user\t0m0.042s\n",
            "sys\t0m2.597s\n",
            "\n",
            "real\t0m23.223s\n",
            "user\t0m0.012s\n",
            "sys\t0m1.989s\n",
            "\n",
            "real\t0m40.959s\n",
            "user\t0m0.077s\n",
            "sys\t0m2.874s\n",
            "\n",
            "real\t0m20.743s\n",
            "user\t0m0.022s\n",
            "sys\t0m2.010s\n",
            "\n",
            "real\t0m0.299s\n",
            "user\t0m0.001s\n",
            "sys\t0m0.007s\n",
            "\n",
            "real\t0m0.015s\n",
            "user\t0m0.002s\n",
            "sys\t0m0.004s\n",
            "data_frame3.csv  dvec8.tar         input_spec5.tar    output_spec4.tar\n",
            "data_frame4.csv  input_phase3.tar  input_spec8.tar    output_spec5.tar\n",
            "data_frame5.csv  input_phase4.tar  output_phase3.tar  output_spec8.tar\n",
            "data_frame8.csv  input_phase5.tar  output_phase4.tar  train_speeches3.data\n",
            "dvec3.tar        input_phase8.tar  output_phase5.tar  train_speeches4.data\n",
            "dvec4.tar        input_spec3.tar   output_phase8.tar  train_speeches5.data\n",
            "dvec5.tar        input_spec4.tar   output_spec3.tar   train_speeches8.data\n",
            "2611\n",
            "2611\n",
            "2611\n",
            "2611\n",
            "2611\n",
            "369 drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches8.data\n",
            "2611 drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame8.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkq6P3N87fuJ"
      },
      "source": [
        "##### 200-251"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2B_whPx7ika",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef645af8-cf95-4b2d-844e-a7a4f96ac866"
      },
      "source": [
        "dataset = 'train' # important global variable\n",
        "speeches = train_speeches # important global variable\n",
        "n = len(train_speeches) # important global variable\n",
        "print(\"number of speakers(train set) : \",n)\n",
        "for i in range(n):\n",
        "  random.shuffle(train_speeches[i])  # shuffle the speeches of all speakers\n",
        "arr = list(range(1,n+1))  # create a list for all speakers\n",
        "\n",
        "import threading\n",
        "data = [] # important global variable\n",
        "parity = 1 # important global variable\n",
        "x = time.time()\n",
        "\n",
        "t = [0]*251\n",
        "\n",
        "for i in arr[200:225]:\n",
        "    t[i] = threading.Thread(target=create_dataset, args=(i,))\n",
        "    t[i].start()\n",
        "\n",
        "for i in arr[200:225]:\n",
        "    t[i].join()\n",
        "\n",
        "y = time.time()\n",
        "print(y-x)\n",
        "save_batch('train',data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of speakers(train set) :  251\n",
            "203\n",
            "205\n",
            "206\n",
            "201\n",
            "202\n",
            "204\n",
            "207\n",
            "223\n",
            "209\n",
            "211\n",
            "210\n",
            "216\n",
            "217\n",
            "215\n",
            "213\n",
            "220\n",
            "212\n",
            "219\n",
            "224\n",
            "214\n",
            "221\n",
            "225\n",
            "208\n",
            "222\n",
            "218\n",
            "1792.4984476566315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmEzSQ6Dhhnf",
        "outputId": "62a1998e-7c39-4e45-8add-3e6b96b16e0f"
      },
      "source": [
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\" | wc -l\n",
        "!wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\"\n",
        "!wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7594\n",
            "7594\n",
            "7594\n",
            "7594\n",
            "7594\n",
            "369 LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\n",
            "7594 LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiU4ITf9inYN",
        "outputId": "b1b8fa9c-ba14-4b02-df3d-f2f674dbd3a5"
      },
      "source": [
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\" | wc -l\n",
        "%ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\" | wc -l\n",
        "!wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\"\n",
        "!wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\"\n",
        "\n",
        "# !rm -r \"LibriSpeech Dataset/LibriSpeech Dev Dataset/\"\n",
        "# !rm -r \"LibriSpeech Dataset/LibriSpeech Test Dataset/\"\n",
        "# !rm -r \"LibriSpeech Dataset/LibriSpeech Train Dataset/LibriSpeech/\"\n",
        "# !rm -r \"LibriSpeech Dataset/train-clean-100.tar.gz\"\n",
        "\n",
        "%ls \"LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "!time tar -cf dvec9.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\"\n",
        "!time cp dvec9.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "!rm dvec9.tar\n",
        "\n",
        "!time tar -cf input_phase9.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\"\n",
        "!time cp input_phase9.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "!rm input_phase9.tar\n",
        "\n",
        "!time tar -cf output_phase9.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\"\n",
        "!time cp output_phase9.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "!rm output_phase9.tar\n",
        "\n",
        "!time tar -cf input_spec9.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\"\n",
        "!time cp input_spec9.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "!rm input_spec9.tar\n",
        "\n",
        "!time tar -cf output_spec9.tar \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\"\n",
        "!time cp output_spec9.tar \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/\"\n",
        "!rm output_spec9.tar\n",
        "\n",
        "!time cp \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\" \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches9.data\"\n",
        "!time cp \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\" \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame9.csv\"\n",
        "\n",
        "%ls \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset\"\n",
        "\n",
        "!tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/dvec9.tar\" | wc -l\n",
        "!tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase9.tar\" | wc -l\n",
        "!tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase9.tar\" | wc -l\n",
        "!tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec9.tar\" | wc -l\n",
        "!tar -tvf \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec9.tar\" | wc -l\n",
        "!wc -l \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches9.data\"\n",
        "!wc -l \"drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame9.csv\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7594\n",
            "7594\n",
            "7594\n",
            "7594\n",
            "7594\n",
            "369 LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\n",
            "7594 LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\n",
            "data_frame.csv  \u001b[0m\u001b[01;34minput_phase_1\u001b[0m/  \u001b[01;34minput_spec_4\u001b[0m/    \u001b[01;34moutput_phase_6\u001b[0m/\n",
            "\u001b[01;34mdvec\u001b[0m/           \u001b[01;34minput_phase_2\u001b[0m/  \u001b[01;34minput_spec_5\u001b[0m/    \u001b[01;34moutput_phase_7\u001b[0m/\n",
            "\u001b[01;34mdvec_0\u001b[0m/         \u001b[01;34minput_phase_3\u001b[0m/  \u001b[01;34minput_spec_6\u001b[0m/    \u001b[01;34moutput_spec\u001b[0m/\n",
            "\u001b[01;34mdvec_1\u001b[0m/         \u001b[01;34minput_phase_4\u001b[0m/  \u001b[01;34minput_spec_7\u001b[0m/    \u001b[01;34moutput_spec_0\u001b[0m/\n",
            "\u001b[01;34mdvec_2\u001b[0m/         \u001b[01;34minput_phase_5\u001b[0m/  \u001b[01;34mLibriSpeech\u001b[0m/     \u001b[01;34moutput_spec_1\u001b[0m/\n",
            "\u001b[01;34mdvec_3\u001b[0m/         \u001b[01;34minput_phase_6\u001b[0m/  \u001b[01;34moutput_phase\u001b[0m/    \u001b[01;34moutput_spec_2\u001b[0m/\n",
            "\u001b[01;34mdvec_4\u001b[0m/         \u001b[01;34minput_phase_7\u001b[0m/  \u001b[01;34moutput_phase_0\u001b[0m/  \u001b[01;34moutput_spec_3\u001b[0m/\n",
            "\u001b[01;34mdvec_5\u001b[0m/         \u001b[01;34minput_spec\u001b[0m/     \u001b[01;34moutput_phase_1\u001b[0m/  \u001b[01;34moutput_spec_4\u001b[0m/\n",
            "\u001b[01;34mdvec_6\u001b[0m/         \u001b[01;34minput_spec_0\u001b[0m/   \u001b[01;34moutput_phase_2\u001b[0m/  \u001b[01;34moutput_spec_5\u001b[0m/\n",
            "\u001b[01;34mdvec_7\u001b[0m/         \u001b[01;34minput_spec_1\u001b[0m/   \u001b[01;34moutput_phase_3\u001b[0m/  \u001b[01;34moutput_spec_6\u001b[0m/\n",
            "\u001b[01;34minput_phase\u001b[0m/    \u001b[01;34minput_spec_2\u001b[0m/   \u001b[01;34moutput_phase_4\u001b[0m/  \u001b[01;34moutput_spec_7\u001b[0m/\n",
            "\u001b[01;34minput_phase_0\u001b[0m/  \u001b[01;34minput_spec_3\u001b[0m/   \u001b[01;34moutput_phase_5\u001b[0m/  train_speeches.data\n",
            "\n",
            "real\t0m1.639s\n",
            "user\t0m0.034s\n",
            "sys\t0m0.260s\n",
            "\n",
            "real\t0m0.065s\n",
            "user\t0m0.004s\n",
            "sys\t0m0.020s\n",
            "\n",
            "real\t1m16.441s\n",
            "user\t0m0.228s\n",
            "sys\t0m8.598s\n",
            "\n",
            "real\t1m26.409s\n",
            "user\t0m0.044s\n",
            "sys\t0m6.359s\n",
            "\n",
            "real\t2m1.147s\n",
            "user\t0m0.286s\n",
            "sys\t0m9.532s\n",
            "\n",
            "real\t1m14.296s\n",
            "user\t0m0.043s\n",
            "sys\t0m5.983s\n",
            "\n",
            "real\t1m56.775s\n",
            "user\t0m0.326s\n",
            "sys\t0m9.527s\n",
            "\n",
            "real\t1m13.736s\n",
            "user\t0m0.061s\n",
            "sys\t0m6.118s\n",
            "\n",
            "real\t1m58.611s\n",
            "user\t0m0.257s\n",
            "sys\t0m9.714s\n",
            "\n",
            "real\t1m16.607s\n",
            "user\t0m0.043s\n",
            "sys\t0m5.975s\n",
            "\n",
            "real\t0m0.030s\n",
            "user\t0m0.003s\n",
            "sys\t0m0.005s\n",
            "\n",
            "real\t0m0.036s\n",
            "user\t0m0.001s\n",
            "sys\t0m0.011s\n",
            "data_frame3.csv  dvec9.tar         input_spec8.tar    output_spec5.tar\n",
            "data_frame4.csv  input_phase3.tar  input_spec9.tar    output_spec8.tar\n",
            "data_frame5.csv  input_phase4.tar  output_phase3.tar  output_spec9.tar\n",
            "data_frame8.csv  input_phase5.tar  output_phase4.tar  train_speeches3.data\n",
            "data_frame9.csv  input_phase8.tar  output_phase5.tar  train_speeches4.data\n",
            "dvec3.tar        input_phase9.tar  output_phase8.tar  train_speeches5.data\n",
            "dvec4.tar        input_spec3.tar   output_phase9.tar  train_speeches8.data\n",
            "dvec5.tar        input_spec4.tar   output_spec3.tar   train_speeches9.data\n",
            "dvec8.tar        input_spec5.tar   output_spec4.tar\n",
            "7594\n",
            "7594\n",
            "7594\n",
            "7594\n",
            "7594\n",
            "369 drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches9.data\n",
            "7594 drive/MyDrive/LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame9.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCKGuZra7kBA"
      },
      "source": [
        "# import threading\n",
        "# data = [] # important global variable\n",
        "# parity = 1 # important global variable\n",
        "# x = time.time()\n",
        "\n",
        "# t = [0]*251\n",
        "\n",
        "# for i in arr[225:250]:\n",
        "#     t[i] = threading.Thread(target=create_dataset, args=(i,))\n",
        "#     t[i].start()\n",
        "\n",
        "# for i in arr[225:250]:\n",
        "#     t[i].join()\n",
        "\n",
        "# y = time.time()\n",
        "# print(y-x)\n",
        "# save_batch('train',data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg1_FoLphidG"
      },
      "source": [
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/dvec/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_phase/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_phase/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/input_spec/\" | wc -l\n",
        "# %ls -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/output_spec/\" | wc -l\n",
        "# !wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/train_speeches.data\"\n",
        "# !wc -l \"LibriSpeech Dataset/LibriSpeech Train Dataset/data_frame.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyG--dju3Sd7"
      },
      "source": [
        "#### Grouping data to avoid gdrive timeout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EIf-3bx3Q26"
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVfiAkwFr2CU"
      },
      "source": [
        "# move files in the dataframe from start_index to end_index to folder for fraction j\n",
        "def move_files(start_index,end_index,j):\n",
        "  df_train = pd.read_csv(os.path.join(path['train'],'data_frame.csv'))\n",
        "  for i in range(start_index,end_index):\n",
        "    for col in ['dvec_path','input_phase_path','input_spec_path','output_phase_path','output_spec_path']:\n",
        "      old_path = df_train[col][i]\n",
        "      new_path = os.path.join(path['train'],col.rsplit('_',1)[0]+\"_\"+str(j),old_path.split('/')[-1])\n",
        "      #print(old_path,\"  \",new_path)\n",
        "      shutil.move(old_path,new_path)\n",
        "      df_train.loc[i,col]=new_path  \n",
        "  df_train.to_csv(os.path.join(path['train'],'data_frame.csv'),index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ_FW-aI1xzt"
      },
      "source": [
        "dataset_train = 'train'\n",
        "df_train = pd.read_csv(os.path.join(path[dataset_train],'data_frame.csv'))\n",
        "num_samples = df_train.shape[0]\n",
        "\n",
        "num_fractions = 8\n",
        "fraction_sizes = num_fractions * [ num_samples//num_fractions ]\n",
        "for i in range(num_samples%num_fractions):\n",
        "  fraction_sizes[i]+=1\n",
        "print(fraction_sizes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ6RVgBqs64i"
      },
      "source": [
        "start_pos = 0\n",
        "for i in range(num_fractions):\n",
        "  end_pos = start_pos + fraction_sizes[i]\n",
        "  move_files(start_pos,end_pos,i)\n",
        "  start_pos = end_pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJYa6dgg3v_e"
      },
      "source": [
        "### Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBfA4JKXkBNi"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxJ4Z6gakD6_"
      },
      "source": [
        "def print_stats(dataset):\n",
        "  df = pd.read_csv(os.path.join(path[dataset],'data_frame.csv'))\n",
        "  num_samples = df.shape[0]\n",
        "  cnt=0 # cnt of the number of times primary speech is same as the reference speech\n",
        "  pairs = {} # cnt of all ordered pairs of speakers\n",
        "  waves=[]\n",
        "  for i in range(num_samples):\n",
        "    ref = df['ref_speech'][i]\n",
        "    pri = df['pri_speech'][i]\n",
        "    sec = df['sec_speech'][i]\n",
        "    ref_wave = ref.split('/')[-1]\n",
        "    pri_wave = pri.split('/')[-1]\n",
        "    sec_wave = sec.split('/')[-1]\n",
        "    waves.append(ref_wave)\n",
        "    waves.append(pri_wave)\n",
        "    waves.append(sec_wave)\n",
        "    pri_spk = pri.split('/')[-3]\n",
        "    sec_spk = sec.split('/')[-3]\n",
        "    if (pri_spk,sec_spk) in pairs:\n",
        "      pairs[(pri_spk,sec_spk)]+=1\n",
        "    else :\n",
        "      pairs[(pri_spk,sec_spk)]=1\n",
        "    if pri_wave == ref_wave:\n",
        "      cnt += 1\n",
        "  waves = len(list(set(waves)))\n",
        "  if dataset == 'train':\n",
        "    speeches = train_speeches\n",
        "  elif dataset == 'dev':\n",
        "    speeches = dev_speeches\n",
        "  else :\n",
        "    speeches = test_speeches\n",
        "  total_speeches = sum([len(spk) for spk in speeches])\n",
        "  print(\"====================\",dataset,\"dataset statistics ====================\")\n",
        "  print(\"Total no. of unique speeches available in LibriSpeech\",dataset,\"dataset :\",total_speeches)\n",
        "  print(\"No. of unique speeches used :\",waves)\n",
        "  print(\"Percentage of total speeches used : {:.2f} %\".format((waves/total_speeches)*100))\n",
        "  print(\"------------------------------------------------------------\")\n",
        "  print(\"Total no. of samples prepared :\",num_samples)\n",
        "  print(\"No. of samples with same primary and reference speech :\",cnt)\n",
        "  print(\"Fraction of such samples as a part of the entire dataset : {:.2f} %\".format((cnt/num_samples)*100))\n",
        "  print(\"-------------------------------------------------------------\")\n",
        "  if all(val == 1 for val in pairs.values()):\n",
        "    print(\"Note: All ordered pairs of primary and secondary speakers are unique\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUNpXaXT7R5N",
        "outputId": "06159107-5c1c-4653-f0bf-192e98ef7094"
      },
      "source": [
        "print_stats('train')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================== train dataset statistics ====================\n",
            "Total no. of unique speeches available in LibriSpeech train dataset : 28539\n",
            "No. of unique speeches used : 12723\n",
            "Percentage of total speeches used : 44.58 %\n",
            "------------------------------------------------------------\n",
            "Total no. of samples prepared : 7593\n",
            "No. of samples with same primary and reference speech : 89\n",
            "Fraction of such samples as a part of the entire dataset : 1.17 %\n",
            "-------------------------------------------------------------\n",
            "Note: All ordered pairs of primary and secondary speakers are unique\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}